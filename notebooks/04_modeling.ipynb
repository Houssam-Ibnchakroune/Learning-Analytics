{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73609d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165b35dd",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e1b78",
   "metadata": {},
   "source": [
    "## Chargement des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "78647b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features chargées :\n",
      "   - X: (23743, 26) (samples × features)\n",
      "   - y: (23743,) (labels)\n",
      "   - Features: 26\n",
      "\n",
      " Distribution des classes :\n",
      "   - Classe 0 (Pass): 8436 (35.5%)\n",
      "   - Classe 1 (Fail): 15307 (64.5%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_path = '../data/processed/X_features.npy'\n",
    "y_path = '../data/processed/y_labels.npy'\n",
    "metadata_path = '../data/processed/features_metadata.json'\n",
    "\n",
    "if not os.path.exists(X_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Les fichiers de features n'existent pas.\\n\"\n",
    "        f\"Exécutez d'abord '03_feature_engineering.ipynb' jusqu'à la fin.\"\n",
    "    )\n",
    "\n",
    "# Charger les données\n",
    "X = np.load(X_path)\n",
    "y = np.load(y_path)\n",
    "\n",
    "# Charger les métadonnées\n",
    "with open(metadata_path, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "    column_names = np.array(metadata['column_names'])\n",
    "    encode_dict = metadata['encode_dict']\n",
    "\n",
    "print(f\"Features chargées :\")\n",
    "print(f\"   - X: {X.shape} (samples × features)\")\n",
    "print(f\"   - y: {y.shape} (labels)\")\n",
    "print(f\"   - Features: {len(column_names)}\")\n",
    "print(f\"\\n Distribution des classes :\")\n",
    "print(f\"   - Classe 0 (Pass): {np.sum(y == 0)} ({100*np.mean(y == 0):.1f}%)\")\n",
    "print(f\"   - Classe 1 (Fail): {np.sum(y == 1)} ({100*np.mean(y == 1):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120417af",
   "metadata": {},
   "source": [
    "Here we use Random Forest simply because it's a good model for classification on tabular data. It's also good out-of-the-box, i.e. not a lot of fussing over hyperparameters. Moreover, there is a straight-forward implementation for permutation feature importance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c03ca38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = RandomForestClassifier(n_estimators = 200,\n",
    "                             max_features = 'sqrt', \n",
    "                             min_samples_split = 10, \n",
    "                            )\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle = True)\n",
    "\n",
    "def train(X,y,reg,kf):\n",
    "    if kf == False: \n",
    "        reg.fit(X,y)\n",
    "    else:\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            reg.fit(X_train,y_train)\n",
    "            print(f'evaluate score: {reg.score(X_test,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "27718e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate score: 0.742682670035797\n",
      "evaluate score: 0.7576331859338808\n",
      "evaluate score: 0.7359444093493367\n",
      "evaluate score: 0.7392586352148273\n",
      "evaluate score: 0.7529486099410277\n"
     ]
    }
   ],
   "source": [
    "train(X,y,reg,kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6793bc91",
   "metadata": {},
   "source": [
    "Our evaluation score is around 75%. Not terribly impressive. Let's try again with more days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "68f7889f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour tester différents seuils de jours (120, 150, 180, 210),\n",
      "modifiez les paramètres (score_deadline,click_deadline) dans le notebook 02_data_preparation.ipynb\n",
      "et réexécutez les notebooks 02 → 03 → 04\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Cette cellule nécessite les fonctions de préparation de données\n",
    "# Pour l'instant, on utilise les features déjà créées (X, y)\n",
    "# Si vous voulez tester différents seuils de jours, \n",
    "# réexécutez le notebook 02 et 03 avec les paramètres souhaités\n",
    "\n",
    "print(\"Pour tester différents seuils de jours (120, 150, 180, 210),\")\n",
    "print(\"modifiez les paramètres (score_deadline,click_deadline) dans le notebook 02_data_preparation.ipynb\")\n",
    "print(\"et réexécutez les notebooks 02 → 03 → 04\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d84a33",
   "metadata": {},
   "source": [
    "As we can expect, more data means higher accuracy, though it also means later intervention if we decide to reach out to the students based on their performance. The sweet spot for our data seems to be 180 days, which would leave 60-80 days before final exam. This might be enough time to help failing students, considering the courses are structured so that majority of the grade depends on the final exam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "448470d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.264</td>\n",
       "      <td>mean_score_day90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.085</td>\n",
       "      <td>quiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.067</td>\n",
       "      <td>highest_education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.064</td>\n",
       "      <td>forumng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.054</td>\n",
       "      <td>url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.054</td>\n",
       "      <td>homepage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.050</td>\n",
       "      <td>resource</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048</td>\n",
       "      <td>code_module</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.038</td>\n",
       "      <td>region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036</td>\n",
       "      <td>code_presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.033</td>\n",
       "      <td>oucollaborate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.029</td>\n",
       "      <td>num_of_prev_attempts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.024</td>\n",
       "      <td>studied_credits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.024</td>\n",
       "      <td>ouwiki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.023</td>\n",
       "      <td>glossary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.018</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.016</td>\n",
       "      <td>age_band</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.014</td>\n",
       "      <td>page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013</td>\n",
       "      <td>dualpane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011</td>\n",
       "      <td>externalquiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.007</td>\n",
       "      <td>disability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.004</td>\n",
       "      <td>ouelluminate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003</td>\n",
       "      <td>htmlactivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>dataplus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000</td>\n",
       "      <td>sharedsubpage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000</td>\n",
       "      <td>repeatactivity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    importance                column\n",
       "25       0.264      mean_score_day90\n",
       "13       0.085                  quiz\n",
       "20       0.067     highest_education\n",
       "5        0.064               forumng\n",
       "17       0.054                   url\n",
       "7        0.054              homepage\n",
       "15       0.050              resource\n",
       "0        0.048           code_module\n",
       "19       0.038                region\n",
       "1        0.036     code_presentation\n",
       "9        0.033         oucollaborate\n",
       "22       0.029  num_of_prev_attempts\n",
       "23       0.024       studied_credits\n",
       "11       0.024                ouwiki\n",
       "6        0.023              glossary\n",
       "18       0.018                gender\n",
       "21       0.016              age_band\n",
       "12       0.014                  page\n",
       "3        0.013              dualpane\n",
       "4        0.011          externalquiz\n",
       "24       0.007            disability\n",
       "10       0.004          ouelluminate\n",
       "8        0.003          htmlactivity\n",
       "2        0.000              dataplus\n",
       "16       0.000         sharedsubpage\n",
       "14       0.000        repeatactivity"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "train(X,y,reg,kf = False)\n",
    "importance = permutation_importance(reg, X, y, n_repeats=10, random_state = 0)\n",
    "importance_mean = np.round(importance['importances_mean'],3)\n",
    "importance_table = pd.DataFrame({'importance': importance_mean,\n",
    "                                 'column': column_names,\n",
    "                                })\n",
    "importance_table.sort_values(by = 'importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c59044",
   "metadata": {},
   "source": [
    "As expected, the most important feature is the average score for each student. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5002a2c0",
   "metadata": {},
   "source": [
    "## Sauvegarde du modèle entraîné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a6c1063c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé : ../models/random_forest_model.pkl\n",
      "Paramètres du modèle :\n",
      "   - n_estimators: 200\n",
      "   - max_features: sqrt\n",
      "   - min_samples_split: 10\n",
      "Métadonnées sauvegardées : ../models/model_metadata.json\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Créer le répertoire models s'il n'existe pas\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "model_path = '../models/random_forest_model.pkl'\n",
    "joblib.dump(reg, model_path)\n",
    "\n",
    "print(f\"Modèle sauvegardé : {model_path}\")\n",
    "print(f\"Paramètres du modèle :\")\n",
    "print(f\"   - n_estimators: {reg.n_estimators}\")\n",
    "print(f\"   - max_features: {reg.max_features}\")\n",
    "print(f\"   - min_samples_split: {reg.min_samples_split}\")\n",
    "\n",
    "# Sauvegarder aussi les métadonnées du modèle\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "model_metadata = {\n",
    "    'model_type': 'RandomForestClassifier',\n",
    "    'n_estimators': reg.n_estimators,\n",
    "    'max_features': reg.max_features,\n",
    "    'min_samples_split': reg.min_samples_split,\n",
    "    'n_features': X.shape[1],\n",
    "    'feature_names': column_names.tolist() if hasattr(column_names, 'tolist') else list(column_names),\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'training_samples': X.shape[0]\n",
    "}\n",
    "\n",
    "metadata_path = '../models/model_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2)\n",
    "\n",
    "print(f\"Métadonnées sauvegardées : {metadata_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
