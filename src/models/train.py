"""
Module pour l'entra√Ænement des mod√®les ML.
"""

import numpy as np
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import KFold, cross_val_score


def train_random_forest(X_train, y_train, config=None):
    """
    Entra√Æne un mod√®le Random Forest.
    
    Args:
        X_train: Features d'entra√Ænement (numpy array)
        y_train: Labels (numpy array)
        config: Dictionnaire avec param√®tres du mod√®le (optionnel)
                {
                    'n_estimators': 200,
                    'max_features': 'sqrt',
                    'min_samples_split': 10,
                    'random_state': 42
                }
        
    Returns:
        model: Mod√®le RandomForestClassifier entra√Æn√©
    """
    if config is None:
        config = {
            'n_estimators': 200,
            'max_features': 'sqrt',
            'min_samples_split': 10,
            'random_state': 42
        }
    
    model = RandomForestClassifier(**config)
    model.fit(X_train, y_train)
    
    return model


def train_with_cross_validation(X_train, y_train, config=None, n_splits=5):
    """
    Entra√Æne un mod√®le Random Forest avec cross-validation.
    
    Args:
        X_train: Features d'entra√Ænement
        y_train: Labels
        config: Param√®tres du mod√®le (optionnel)
        n_splits: Nombre de folds pour K-Fold (d√©faut: 5)
        
    Returns:
        model: Mod√®le entra√Æn√© sur l'ensemble complet
        cv_scores: Liste des scores de validation crois√©e
    """
    if config is None:
        config = {
            'n_estimators': 200,
            'max_features': 'sqrt',
            'min_samples_split': 10,
            'random_state': 42
        }
    
    model = RandomForestClassifier(**config)
    
    # Cross-validation
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)
    cv_scores = []
    
    print(f"üîÑ Cross-validation avec {n_splits} folds...")
    for fold, (train_index, test_index) in enumerate(kf.split(X_train), 1):
        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]
        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]
        
        model.fit(X_train_fold, y_train_fold)
        score = model.score(X_test_fold, y_test_fold)
        cv_scores.append(score)
        print(f"  Fold {fold}: Accuracy = {score:.4f}")
    
    print(f"\n‚úÖ Moyenne CV: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})")
    
    # Entra√Ænement final sur l'ensemble complet
    model.fit(X_train, y_train)
    
    return model, cv_scores


def save_model(model, filepath):
    """
    Sauvegarde un mod√®le entra√Æn√©.
    
    Args:
        model: Mod√®le scikit-learn
        filepath: Chemin de sauvegarde (ex: 'models/random_forest_day180.pkl')
    """
    joblib.dump(model, filepath)
    print(f"‚úÖ Mod√®le sauvegard√© : {filepath}")


def load_model(filepath):
    """
    Charge un mod√®le sauvegard√©.
    
    Args:
        filepath: Chemin du mod√®le (ex: 'models/random_forest_day180.pkl')
        
    Returns:
        model: Mod√®le charg√©
    """
    model = joblib.load(filepath)
    print(f"‚úÖ Mod√®le charg√© : {filepath}")
    return model


# Exemple d'utilisation
if __name__ == "__main__":
    import sys
    sys.path.append('..')
    
    # Charger les donn√©es (exemple)
    # X_train = np.load('../data/processed/X_train.npy')
    # y_train = np.load('../data/processed/y_train.npy')
    
    # Configuration du mod√®le
    config = {
        'n_estimators': 200,
        'max_features': 'sqrt',
        'min_samples_split': 10,
        'random_state': 42
    }
    
    # Entra√Ænement avec cross-validation
    # model, cv_scores = train_with_cross_validation(X_train, y_train, config, n_splits=5)
    
    # Sauvegarde
    # save_model(model, '../models/random_forest_day180.pkl')
    
    print("Module train.py pr√™t √† l'emploi !")